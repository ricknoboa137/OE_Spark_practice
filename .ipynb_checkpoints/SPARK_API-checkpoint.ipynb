{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc563b6",
   "metadata": {},
   "source": [
    "# SPARK API \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b31e0a",
   "metadata": {},
   "source": [
    "## Dokumentation: \n",
    "\n",
    "- RDD API\n",
    "    - https://spark.apache.org/docs/latest/rdd-programming-guide.html\n",
    "    - https://spark.apache.org/docs/latest/api/python/reference/pyspark.html#rdd-apis\n",
    "    - https://intellipaat.com/blog/tutorial/spark-tutorial/programming-with-rdds/\n",
    "    \n",
    "- Spark SQL, Dataframe API: https://spark.apache.org/docs/latest/sql-programming-guide.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b04d5180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"SPARK_API\")\n",
    "spark = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eedce95",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421eb63",
   "metadata": {},
   "source": [
    "## RDD API\n",
    "\n",
    "RDD (Resilient Distributed Dataset) is the core data structure of Spark, which allows distributed processing of data on the Spark cluster. An RDD is a non-modifiable, partitioned dataset with no strict ordering between its elements.\n",
    "\n",
    "The RDD supports the following basic operations:\n",
    "\n",
    " Transformation: RDDs can be transformed using transformation operations. RDDs cannot be modified, so each transformation operation results in a new RDD.\n",
    "- Action: RDDs can be subject to action operations, the result of which is returned to the Spark control program.\n",
    "\n",
    "RDDs can be created as follows:\n",
    "\n",
    "- RDDs can be created from data sources such as text files, databases, or Hadoop HDFS.\n",
    "- RDDs can be created by transformations of existing RDDs.\n",
    "- RDDs can be created from data in the Spark driver.\n",
    "\n",
    "The RDD API is part of PySpark and provides the following functionality for managing RDDs (Resilient Distributed Datasets):\n",
    "\n",
    "- Transformations: are used to modify the data in RDDs. For example, map(), filter(), flatMap(), reduceByKey(), etc.\n",
    "\n",
    "- Actions: are used to write out the data of RDDs or to retrieve the results. For example, collect (), take (), first (), count (), etc.\n",
    "\n",
    "- Persistence: can be used to cache RDDs or to save data. For example, cache(), persist(), saveAsTextFile(), etc.\n",
    "\n",
    "- Partitioning: RDDs are used to partition and move data in a cluster. Examples are repartition (), coalesce (), etc.\n",
    "\n",
    "\n",
    "- RDD operations: RDDs provide basic operations for processing data. For example, union (), intersection (), subtract (), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22acd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_rdd = spark.read.format(\"parquet\").load(\"titanic_parquet\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77952e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_rdd.show()\n",
    "\n",
    "# no show function available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dfbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_rdd.printSchema()\n",
    "\n",
    "# no function printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c265a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_rdd.foreach(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138aa404",
   "metadata": {},
   "source": [
    "### RDD API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf523d15",
   "metadata": {},
   "source": [
    "| Function | description |\n",
    "|---|---|\n",
    "| map(func) | Returns a new RDD while executing the function passed in the parameter |\n",
    "| flatMap(func) | |\n",
    "| filter(func) | Returns with a new RDD, while only those elements will be included for which the function returned True |\n",
    "| reduceByKey(func) | Aggregate values by key |\n",
    "| groupByKey() | Convert Key/Value pair to Key/List |\n",
    "| union(otherDataset) | Combines both the current RDD and the RDD passed to the parameter |\n",
    "| intersection(otherDataset) | Returns the common elements |\n",
    "| distinct() | Removes duplicate rows |\n",
    "| coalesce(numPartitions) | Change the partitions to the specified number without reshuffling |\n",
    "| repartition(numPartitions) | Change the partitions to the specified number, with reshuffling |\n",
    "| reduce( func) | Aggregate mapped data |\n",
    "| collect() | Retrieve data in rdd into python list |\n",
    "| count() | Return the number of rows in RDD in python |\n",
    "| first() | Returns the first element |\n",
    "| take( n) | Returns N elements |\n",
    "| foreach( func) | Executes the func function on all elements of the RDD |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062cbf54",
   "metadata": {},
   "source": [
    "### map function\n",
    "\n",
    "The map() function is a basic transformation of PySpark RDDs. Using map(), all elements in an RDD can be transformed into a list of elements in a new RDD.\n",
    "\n",
    "The new RDD returned by map() is the transformed version of the original RDD. The original RDD is not modified.\n",
    "\n",
    "The map() function has a single parameter, which can be a lambda expression, a function or a method. The lambda expression is usually the simplest solution, especially if the transformation is short and simple. A function or method may also be used if the transformation is more complex and/or requires more parameters.\n",
    "\n",
    "The use of the map() function is very useful in preparing the data and converting, extracting and transforming dates or numbers into the desired format. When using the map() function, it is important to note that transformations are only performed when action functions (e.g. collect(), count(), saveAsTextFile()) are called with RDD. This means that the map() function does not perform all computations immediately, but only when the RDD is evaluated in some way.\n",
    "\n",
    "### filter function\n",
    "The filter() function is used to select from the elements in the RDD only those that satisfy a given condition, which is a lambda expression or a function. Those elements that match the condition are kept in the RDD, while those that do not are discarded.\n",
    "\n",
    "\n",
    "\n",
    "### count function\n",
    "The count() function of PySpark RDDs is one of the basic actions to count the number of elements in the RDD.\n",
    "\n",
    "The count() function has no parameters, and returns an integer number that specifies the number of elements in the RDD. This is useful because it allows the size of the RDD to be checked, which can be particularly important when analysing and processing data.\n",
    "\n",
    "The count() function is very fast, as it does not check all the elements in the RDD, but only their number. This function can be used to check the size of the RDD and to review and examine data from the RDD.\n",
    "\n",
    "If the RDD is empty, the result will be 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e7384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Braund, Mr. Owen Harris', 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', 'Heikkinen, Miss. Laina', 'Futrelle, Mrs. Jacques Heath (Lily May Peel)', 'Allen, Mr. William Henry', 'Moran, Mr. James', 'McCarthy, Mr. Timothy J', 'Palsson, Master. Gosta Leonard', 'Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)', 'Nasser, Mrs. Nicholas (Adele Achem)', 'Sandstrom, Miss. Marguerite Rut', 'Bonnell, Miss. Elizabeth', 'Saundercock, Mr. William Henry', 'Andersson, Mr. Anders Johan', 'Vestrom, Miss. Hulda Amanda Adolfina', 'Hewlett, Mrs. (Mary D Kingcome) ', 'Rice, Master. Eugene', 'Williams, Mr. Charles Eugene', 'Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)', 'Masselmani, Mrs. Fatima', 'Fynney, Mr. Joseph J', 'Beesley, Mr. Lawrence', '\"McGowan, Miss. Anna \"\"Annie\"\"\"', 'Sloper, Mr. William Thompson', 'Palsson, Miss. Torborg Danira', 'Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson)', 'Emir, Mr. Farred Chehab', 'Fortune, Mr. Charles Alexander', '\"O\\'Dwyer, Miss. Ellen \"\"Nellie\"\"\"', 'Todoroff, Mr. Lalio', 'Uruchurtu, Don. Manuel E', 'Spencer, Mrs. William Augustus (Marie Eugenie)', 'Glynn, Miss. Mary Agatha', 'Wheadon, Mr. Edward H', 'Meyer, Mr. Edgar Joseph', 'Holverson, Mr. Alexander Oskar', 'Mamee, Mr. Hanna', 'Cann, Mr. Ernest Charles', 'Vander Planke, Miss. Augusta Maria', 'Nicola-Yarred, Miss. Jamila', 'Ahlin, Mrs. Johan (Johanna Persdotter Larsson)', 'Turpin, Mrs. William John Robert (Dorothy Ann Wonnacott)', 'Kraeff, Mr. Theodor', 'Laroche, Miss. Simonne Marie Anne Andree', 'Devaney, Miss. Margaret Delia', 'Rogers, Mr. William John', 'Lennon, Mr. Denis', \"O'Driscoll, Miss. Bridget\", 'Samaan, Mr. Youssef', 'Arnold-Franchi, Mrs. Josef (Josefine Franchi)', 'Panula, Master. Juha Niilo', 'Nosworthy, Mr. Richard Cater', 'Harper, Mrs. Henry Sleeper (Myna Haxtun)', 'Faunthorpe, Mrs. Lizzie (Elizabeth Anne Wilkinson)', 'Ostby, Mr. Engelhart Cornelius', 'Woolner, Mr. Hugh', 'Rugg, Miss. Emily', 'Novel, Mr. Mansouer', 'West, Miss. Constance Mirium', 'Goodwin, Master. William Frederick', 'Sirayanian, Mr. Orsen', 'Icard, Miss. Amelie', 'Harris, Mr. Henry Birkhardt', 'Skoog, Master. Harald', 'Stewart, Mr. Albert A', 'Moubarek, Master. Gerios', 'Nye, Mrs. (Elizabeth Ramell)', 'Crease, Mr. Ernest James', 'Andersson, Miss. Erna Alexandra', 'Kink, Mr. Vincenz', 'Jenkin, Mr. Stephen Curnow', 'Goodwin, Miss. Lillian Amy', 'Hood, Mr. Ambrose Jr', 'Chronopoulos, Mr. Apostolos', 'Bing, Mr. Lee', 'Moen, Mr. Sigurd Hansen', 'Staneff, Mr. Ivan', 'Moutal, Mr. Rahamin Haim', 'Caldwell, Master. Alden Gates', 'Dowdell, Miss. Elizabeth', 'Waelens, Mr. Achille', 'Sheerlinck, Mr. Jan Baptist', 'McDermott, Miss. Brigdet Delia', 'Carrau, Mr. Francisco M', 'Ilett, Miss. Bertha', 'Backstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)', 'Ford, Mr. William Neal', 'Slocovski, Mr. Selman Francis', 'Fortune, Miss. Mabel Helen', 'Celotti, Mr. Francesco', 'Christmann, Mr. Emil', 'Andreasson, Mr. Paul Edvin', 'Chaffee, Mr. Herbert Fuller', 'Dean, Mr. Bertram Frank', 'Coxon, Mr. Daniel', 'Shorney, Mr. Charles Joseph', 'Goldschmidt, Mr. George B', 'Greenfield, Mr. William Bertram', 'Doling, Mrs. John T (Ada Julia Bone)', 'Kantor, Mr. Sinai', 'Petranec, Miss. Matilda', '\"Petroff, Mr. Pastcho (\"\"Pentcho\"\")\"', 'White, Mr. Richard Frasar', 'Johansson, Mr. Gustaf Joel', 'Gustafsson, Mr. Anders Vilhelm', 'Mionoff, Mr. Stoytcho', 'Salkjelsvik, Miss. Anna Kristine', 'Moss, Mr. Albert Johan', 'Rekic, Mr. Tido', 'Moran, Miss. Bertha', 'Porter, Mr. Walter Chamberlain', 'Zabour, Miss. Hileni', 'Barton, Mr. David John', 'Jussila, Miss. Katriina', 'Attalah, Miss. Malake', 'Pekoniemi, Mr. Edvard', 'Connors, Mr. Patrick', 'Turpin, Mr. William John Robert', 'Baxter, Mr. Quigg Edmond', 'Andersson, Miss. Ellis Anna Maria', 'Hickman, Mr. Stanley George', 'Moore, Mr. Leonard Charles', 'Nasser, Mr. Nicholas', 'Webber, Miss. Susan', 'White, Mr. Percival Wayland', 'Nicola-Yarred, Master. Elias', 'McMahon, Mr. Martin', 'Madsen, Mr. Fridtjof Arne', 'Peter, Miss. Anna', 'Ekstrom, Mr. Johan', 'Drazenoic, Mr. Jozef', 'Coelho, Mr. Domingos Fernandeo', 'Robins, Mrs. Alexander A (Grace Charity Laury)', 'Weisz, Mrs. Leopold (Mathilde Francoise Pede)', 'Sobey, Mr. Samuel James Hayden', 'Richard, Mr. Emile', 'Newsom, Miss. Helen Monypeny', 'Futrelle, Mr. Jacques Heath', 'Osen, Mr. Olaf Elon', 'Giglio, Mr. Victor', 'Boulos, Mrs. Joseph (Sultana)', 'Nysten, Miss. Anna Sofia', 'Hakkarainen, Mrs. Pekka Pietari (Elin Matilda Dolck)', 'Burke, Mr. Jeremiah', 'Andrew, Mr. Edgardo Samuel', 'Nicholls, Mr. Joseph Charles', '\"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"', '\"Ford, Miss. Robina Maggie \"\"Ruby\"\"\"', '\"Navratil, Mr. Michel (\"\"Louis M Hoffman\"\")\"', 'Byles, Rev. Thomas Roussel Davids', 'Bateman, Rev. Robert James', 'Pears, Mrs. Thomas (Edith Wearne)', 'Meo, Mr. Alfonzo', 'van Billiard, Mr. Austin Blyler', 'Olsen, Mr. Ole Martin', 'Williams, Mr. Charles Duane', '\"Gilnagh, Miss. Katherine \"\"Katie\"\"\"', 'Corn, Mr. Harry', 'Smiljanic, Mr. Mile', 'Sage, Master. Thomas Henry', 'Cribb, Mr. John Hatfield', '\"Watt, Mrs. James (Elizabeth \"\"Bessie\"\" Inglis Milne)\"', 'Bengtsson, Mr. John Viktor', 'Calic, Mr. Jovo', 'Panula, Master. Eino Viljami', '\"Goldsmith, Master. Frank John William \"\"Frankie\"\"\"', 'Chibnall, Mrs. (Edith Martha Bowerman)', 'Skoog, Mrs. William (Anna Bernhardina Karlsson)', 'Baumann, Mr. John D', 'Ling, Mr. Lee', 'Van der hoef, Mr. Wyckoff', 'Rice, Master. Arthur', 'Johnson, Miss. Eleanor Ileen', 'Sivola, Mr. Antti Wilhelm', 'Smith, Mr. James Clinch', 'Klasen, Mr. Klas Albin', 'Lefebre, Master. Henry Forbes', 'Isham, Miss. Ann Elizabeth', 'Hale, Mr. Reginald', 'Leonard, Mr. Lionel', 'Sage, Miss. Constance Gladys', 'Pernot, Mr. Rene', 'Asplund, Master. Clarence Gustaf Hugo', 'Becker, Master. Richard F', 'Kink-Heilmann, Miss. Luise Gretchen', 'Rood, Mr. Hugh Roscoe', '\"O\\'Brien, Mrs. Thomas (Johanna \"\"Hannah\"\" Godfrey)\"', '\"Romaine, Mr. Charles Hallace (\"\"Mr C Rolmane\"\")\"', 'Bourke, Mr. John', 'Turcin, Mr. Stjepan', 'Pinsky, Mrs. (Rosa)', 'Carbines, Mr. William', 'Andersen-Jensen, Miss. Carla Christine Nielsine', 'Navratil, Master. Michel M', 'Brown, Mrs. James Joseph (Margaret Tobin)', 'Lurette, Miss. Elise', 'Mernagh, Mr. Robert', 'Olsen, Mr. Karl Siegwart Andreas', '\"Madigan, Miss. Margaret \"\"Maggie\"\"\"', '\"Yrois, Miss. Henriette (\"\"Mrs Harbeck\"\")\"', 'Vande Walle, Mr. Nestor Cyriel', 'Sage, Mr. Frederick', 'Johanson, Mr. Jakob Alfred', 'Youseff, Mr. Gerious', '\"Cohen, Mr. Gurshon \"\"Gus\"\"\"', 'Strom, Miss. Telma Matilda', 'Backstrom, Mr. Karl Alfred', 'Albimona, Mr. Nassef Cassem', '\"Carr, Miss. Helen \"\"Ellen\"\"\"', 'Blank, Mr. Henry', 'Ali, Mr. Ahmed', 'Cameron, Miss. Clear Annie', 'Perkin, Mr. John Henry', 'Givard, Mr. Hans Kristensen', 'Kiernan, Mr. Philip', 'Newell, Miss. Madeleine', 'Honkanen, Miss. Eliina', 'Jacobsohn, Mr. Sidney Samuel', 'Bazzani, Miss. Albina', 'Harris, Mr. Walter', 'Sunderland, Mr. Victor Francis', 'Bracken, Mr. James H', 'Green, Mr. George Henry', 'Nenkoff, Mr. Christo', 'Hoyt, Mr. Frederick Maxfield', 'Berglund, Mr. Karl Ivar Sven', 'Mellors, Mr. William John', '\"Lovell, Mr. John Hall (\"\"Henry\"\")\"', 'Fahlstrom, Mr. Arne Jonas', 'Lefebre, Miss. Mathilde', 'Harris, Mrs. Henry Birkhardt (Irene Wallach)', 'Larsson, Mr. Bengt Edvin', 'Sjostedt, Mr. Ernst Adolf', 'Asplund, Miss. Lillian Gertrud', 'Leyson, Mr. Robert William Norman', 'Harknett, Miss. Alice Phoebe', 'Hold, Mr. Stephen', '\"Collyer, Miss. Marjorie \"\"Lottie\"\"\"', 'Pengelly, Mr. Frederick William', 'Hunt, Mr. George Henry', 'Zabour, Miss. Thamine', '\"Murphy, Miss. Katherine \"\"Kate\"\"\"', 'Coleridge, Mr. Reginald Charles', 'Maenpaa, Mr. Matti Alexanteri', 'Attalah, Mr. Sleiman', 'Minahan, Dr. William Edward', 'Lindahl, Miss. Agda Thorilda Viktoria', 'Hamalainen, Mrs. William (Anna)', 'Beckwith, Mr. Richard Leonard', 'Carter, Rev. Ernest Courtenay', 'Reed, Mr. James George', 'Strom, Mrs. Wilhelm (Elna Matilda Persson)', 'Stead, Mr. William Thomas', 'Lobb, Mr. William Arthur', 'Rosblom, Mrs. Viktor (Helena Wilhelmina)', 'Touma, Mrs. Darwis (Hanne Youssef Razi)', 'Thorne, Mrs. Gertrude Maybelle', 'Cherry, Miss. Gladys', 'Ward, Miss. Anna', 'Parrish, Mrs. (Lutie Davis)', 'Smith, Mr. Thomas', 'Asplund, Master. Edvin Rojj Felix', 'Taussig, Mr. Emil', 'Harrison, Mr. William', 'Henry, Miss. Delia', 'Reeves, Mr. David', 'Panula, Mr. Ernesti Arvid', 'Persson, Mr. Ernst Ulrik', 'Graham, Mrs. William Thompson (Edith Junkins)', 'Bissette, Miss. Amelia', 'Cairns, Mr. Alexander', 'Tornquist, Mr. William Henry', 'Mellinger, Mrs. (Elizabeth Anne Maidment)', 'Natsch, Mr. Charles H', '\"Healy, Miss. Hanora \"\"Nora\"\"\"', 'Andrews, Miss. Kornelia Theodosia', 'Lindblom, Miss. Augusta Charlotta', '\"Parkes, Mr. Francis \"\"Frank\"\"\"', 'Rice, Master. Eric', 'Abbott, Mrs. Stanton (Rosa Hunt)', 'Duane, Mr. Frank', 'Olsson, Mr. Nils Johan Goransson', 'de Pelsmaeker, Mr. Alfons', 'Dorking, Mr. Edward Arthur', 'Smith, Mr. Richard William', 'Stankovic, Mr. Ivan', 'de Mulder, Mr. Theodore', 'Naidenoff, Mr. Penko', 'Hosono, Mr. Masabumi', 'Connolly, Miss. Kate', '\"Barber, Miss. Ellen \"\"Nellie\"\"\"', 'Bishop, Mrs. Dickinson H (Helen Walton)', 'Levy, Mr. Rene Jacques', 'Haas, Miss. Aloisia', 'Mineff, Mr. Ivan', 'Lewy, Mr. Ervin G', 'Hanna, Mr. Mansour', 'Allison, Miss. Helen Loraine', 'Saalfeld, Mr. Adolphe', 'Baxter, Mrs. James (Helene DeLaudeniere Chaput)', '\"Kelly, Miss. Anna Katherine \"\"Annie Kate\"\"\"', 'McCoy, Mr. Bernard', 'Johnson, Mr. William Cahoone Jr', 'Keane, Miss. Nora A', '\"Williams, Mr. Howard Hugh \"\"Harry\"\"\"', 'Allison, Master. Hudson Trevor', 'Fleming, Miss. Margaret', 'Penasco y Castellana, Mrs. Victor de Satode (Maria Josefa Perez de Soto y Vallejo)', 'Abelson, Mr. Samuel', 'Francatelli, Miss. Laura Mabel', 'Hays, Miss. Margaret Bechstein', 'Ryerson, Miss. Emily Borie', 'Lahtinen, Mrs. William (Anna Sylfven)', 'Hendekovic, Mr. Ignjac', 'Hart, Mr. Benjamin', 'Nilsson, Miss. Helmina Josefina', 'Kantor, Mrs. Sinai (Miriam Sternin)', 'Moraweck, Dr. Ernest', 'Wick, Miss. Mary Natalie', 'Spedden, Mrs. Frederic Oakley (Margaretta Corning Stone)', 'Dennis, Mr. Samuel', 'Danoff, Mr. Yoto', 'Slayter, Miss. Hilda Mary', 'Caldwell, Mrs. Albert Francis (Sylvia Mae Harbaugh)', 'Sage, Mr. George John Jr', 'Young, Miss. Marie Grice', 'Nysveen, Mr. Johan Hansen', 'Ball, Mrs. (Ada E Hall)', 'Goldsmith, Mrs. Frank John (Emily Alice Brown)', 'Hippach, Miss. Jean Gertrude', 'McCoy, Miss. Agnes', 'Partner, Mr. Austen', 'Graham, Mr. George Edward', 'Vander Planke, Mr. Leo Edmondus', 'Frauenthal, Mrs. Henry William (Clara Heinsheimer)', 'Denkoff, Mr. Mitto', 'Pears, Mr. Thomas Clinton', 'Burns, Miss. Elizabeth Margaret', 'Dahl, Mr. Karl Edwart', 'Blackwell, Mr. Stephen Weart', 'Navratil, Master. Edmond Roger', 'Fortune, Miss. Alice Elizabeth', 'Collander, Mr. Erik Gustaf', 'Sedgwick, Mr. Charles Frederick Waddington', 'Fox, Mr. Stanley Hubert', '\"Brown, Miss. Amelia \"\"Mildred\"\"\"', 'Smith, Miss. Marion Elsie', 'Davison, Mrs. Thomas Henry (Mary E Finck)', '\"Coutts, Master. William Loch \"\"William\"\"\"', 'Dimic, Mr. Jovan', 'Odahl, Mr. Nils Martin', 'Williams-Lambert, Mr. Fletcher Fellows', 'Elias, Mr. Tannous', 'Arnold-Franchi, Mr. Josef', 'Yousif, Mr. Wazli', 'Vanden Steen, Mr. Leo Peter', 'Bowerman, Miss. Elsie Edith', 'Funk, Miss. Annie Clemmer', 'McGovern, Miss. Mary', '\"Mockler, Miss. Helen Mary \"\"Ellie\"\"\"', 'Skoog, Mr. Wilhelm', 'del Carlo, Mr. Sebastiano', 'Barbara, Mrs. (Catherine David)', 'Asim, Mr. Adola', \"O'Brien, Mr. Thomas\", 'Adahl, Mr. Mauritz Nils Martin', 'Warren, Mrs. Frank Manley (Anna Sophia Atkinson)', 'Moussa, Mrs. (Mantoura Boulos)', 'Jermyn, Miss. Annie', 'Aubart, Mme. Leontine Pauline', 'Harder, Mr. George Achilles', 'Wiklund, Mr. Jakob Alfred', 'Beavan, Mr. William Thomas', 'Ringhini, Mr. Sante', 'Palsson, Miss. Stina Viola', 'Meyer, Mrs. Edgar Joseph (Leila Saks)', 'Landergren, Miss. Aurora Adelia', 'Widener, Mr. Harry Elkins', 'Betros, Mr. Tannous', 'Gustafsson, Mr. Karl Gideon', 'Bidois, Miss. Rosalie', '\"Nakid, Miss. Maria (\"\"Mary\"\")\"', 'Tikkanen, Mr. Juho', 'Holverson, Mrs. Alexander Oskar (Mary Aline Towner)', 'Plotcharsky, Mr. Vasil', 'Davies, Mr. Charles Henry', 'Goodwin, Master. Sidney Leonard', 'Buss, Miss. Kate', 'Sadlier, Mr. Matthew', 'Lehmann, Miss. Bertha', 'Carter, Mr. William Ernest', 'Jansson, Mr. Carl Olof', 'Gustafsson, Mr. Johan Birger', 'Newell, Miss. Marjorie', 'Sandstrom, Mrs. Hjalmar (Agnes Charlotta Bengtsson)', 'Johansson, Mr. Erik', 'Olsson, Miss. Elina', 'McKane, Mr. Peter David', 'Pain, Dr. Alfred', 'Trout, Mrs. William H (Jessie L)', 'Niskanen, Mr. Juha', 'Adams, Mr. John', 'Jussila, Miss. Mari Aina', 'Hakkarainen, Mr. Pekka Pietari', 'Oreskovic, Miss. Marija', 'Gale, Mr. Shadrach', 'Widegren, Mr. Carl/Charles Peter', 'Richards, Master. William Rowe', 'Birkeland, Mr. Hans Martin Monsen', 'Lefebre, Miss. Ida', 'Sdycoff, Mr. Todor', 'Hart, Mr. Henry', 'Minahan, Miss. Daisy E', 'Cunningham, Mr. Alfred Fleming', 'Sundman, Mr. Johan Julian', 'Meek, Mrs. Thomas (Annie Louise Rowley)', 'Drew, Mrs. James Vivian (Lulu Thorne Christian)', 'Silven, Miss. Lyyli Karoliina', 'Matthews, Mr. William John', 'Van Impe, Miss. Catharina', 'Gheorgheff, Mr. Stanio', 'Charters, Mr. David', 'Zimmerman, Mr. Leo', 'Danbom, Mrs. Ernst Gilbert (Anna Sigrid Maria Brogren)', 'Rosblom, Mr. Viktor Richard', 'Wiseman, Mr. Phillippe', 'Clarke, Mrs. Charles V (Ada Maria Winfield)', '\"Phillips, Miss. Kate Florence (\"\"Mrs Kate Louise Phillips Marshall\"\")\"', 'Flynn, Mr. James', 'Pickard, Mr. Berk (Berk Trembisky)', 'Bjornstrom-Steffansson, Mr. Mauritz Hakan', 'Thorneycroft, Mrs. Percival (Florence Kate White)', 'Louch, Mrs. Charles Alexander (Alice Adelaide Slow)', 'Kallio, Mr. Nikolai Erland', 'Silvey, Mr. William Baird', 'Carter, Miss. Lucile Polk', '\"Ford, Miss. Doolina Margaret \"\"Daisy\"\"\"', 'Richards, Mrs. Sidney (Emily Hocking)', 'Fortune, Mr. Mark', 'Kvillner, Mr. Johan Henrik Johannesson', 'Hart, Mrs. Benjamin (Esther Ada Bloomfield)', 'Hampe, Mr. Leon', 'Petterson, Mr. Johan Emil', 'Reynaldo, Ms. Encarnacion', 'Johannesen-Bratthammer, Mr. Bernt', 'Dodge, Master. Washington', 'Mellinger, Miss. Madeleine Violet', 'Seward, Mr. Frederic Kimber', 'Baclini, Miss. Marie Catherine', 'Peuchen, Major. Arthur Godfrey', 'West, Mr. Edwy Arthur', 'Hagland, Mr. Ingvald Olai Olsen', 'Foreman, Mr. Benjamin Laventall', 'Goldenberg, Mr. Samuel L', 'Peduzzi, Mr. Joseph', 'Jalsevac, Mr. Ivan', 'Millet, Mr. Francis Davis', 'Kenyon, Mrs. Frederick R (Marion)', 'Toomey, Miss. Ellen', \"O'Connor, Mr. Maurice\", 'Anderson, Mr. Harry', 'Morley, Mr. William', 'Gee, Mr. Arthur H', 'Milling, Mr. Jacob Christian', 'Maisner, Mr. Simon', 'Goncalves, Mr. Manuel Estanslas', 'Campbell, Mr. William', 'Smart, Mr. John Montgomery', 'Scanlan, Mr. James', 'Baclini, Miss. Helene Barbara', 'Keefe, Mr. Arthur', 'Cacic, Mr. Luka', 'West, Mrs. Edwy Arthur (Ada Mary Worth)', 'Jerwan, Mrs. Amin S (Marie Marthe Thuillard)', 'Strandberg, Miss. Ida Sofia', 'Clifford, Mr. George Quincy', 'Renouf, Mr. Peter Henry', 'Braund, Mr. Lewis Richard', 'Karlsson, Mr. Nils August', 'Hirvonen, Miss. Hildur E', 'Goodwin, Master. Harold Victor', '\"Frost, Mr. Anthony Wood \"\"Archie\"\"\"', 'Rouse, Mr. Richard Henry', 'Turkula, Mrs. (Hedwig)', 'Bishop, Mr. Dickinson H', 'Lefebre, Miss. Jeannie', 'Hoyt, Mrs. Frederick Maxfield (Jane Anne Forby)', 'Kent, Mr. Edward Austin', 'Somerton, Mr. Francis William', '\"Coutts, Master. Eden Leslie \"\"Neville\"\"\"', 'Hagland, Mr. Konrad Mathias Reiersen', 'Windelov, Mr. Einar', 'Molson, Mr. Harry Markland', 'Artagaveytia, Mr. Ramon', 'Stanley, Mr. Edward Roland', 'Yousseff, Mr. Gerious', 'Eustis, Miss. Elizabeth Mussey', 'Shellard, Mr. Frederick William', 'Allison, Mrs. Hudson J C (Bessie Waldo Daniels)', 'Svensson, Mr. Olof', 'Calic, Mr. Petar', 'Canavan, Miss. Mary', \"O'Sullivan, Miss. Bridget Mary\", 'Laitinen, Miss. Kristina Sofia', 'Maioni, Miss. Roberta', 'Penasco y Castellana, Mr. Victor de Satode', 'Quick, Mrs. Frederick Charles (Jane Richards)', '\"Bradley, Mr. George (\"\"George Arthur Brayton\"\")\"', 'Olsen, Mr. Henry Margido', 'Lang, Mr. Fang', 'Daly, Mr. Eugene Patrick', 'Webber, Mr. James', 'McGough, Mr. James Robert', 'Rothschild, Mrs. Martin (Elizabeth L. Barrett)', 'Coleff, Mr. Satio', 'Walker, Mr. William Anderson', 'Lemore, Mrs. (Amelia Milley)', 'Ryan, Mr. Patrick', '\"Angle, Mrs. William A (Florence \"\"Mary\"\" Agnes Hughes)\"', 'Pavlovic, Mr. Stefo', 'Perreault, Miss. Anne', 'Vovk, Mr. Janko', 'Lahoud, Mr. Sarkis', 'Hippach, Mrs. Louis Albert (Ida Sophia Fischer)', 'Kassem, Mr. Fared', 'Farrell, Mr. James', 'Ridsdale, Miss. Lucy', 'Farthing, Mr. John', 'Salonen, Mr. Johan Werner', 'Hocking, Mr. Richard George', 'Quick, Miss. Phyllis May', 'Toufik, Mr. Nakli', 'Elias, Mr. Joseph Jr', 'Peter, Mrs. Catherine (Catherine Rizk)', 'Cacic, Miss. Marija', 'Hart, Miss. Eva Miriam', 'Butt, Major. Archibald Willingham', 'LeRoy, Miss. Bertha', 'Risien, Mr. Samuel Beard', 'Frolicher, Miss. Hedwig Margaritha', 'Crosby, Miss. Harriet R', 'Andersson, Miss. Ingeborg Constanzia', 'Andersson, Miss. Sigrid Elisabeth', 'Beane, Mr. Edward', 'Douglas, Mr. Walter Donald', 'Nicholson, Mr. Arthur Ernest', 'Beane, Mrs. Edward (Ethel Clarke)', 'Padro y Manent, Mr. Julian', 'Goldsmith, Mr. Frank John', 'Davies, Master. John Morgan Jr', 'Thayer, Mr. John Borland Jr', 'Sharp, Mr. Percival James R', \"O'Brien, Mr. Timothy\", '\"Leeni, Mr. Fahim (\"\"Philip Zenni\"\")\"', 'Ohman, Miss. Velin', 'Wright, Mr. George', '\"Duff Gordon, Lady. (Lucille Christiana Sutherland) (\"\"Mrs Morgan\"\")\"', 'Robbins, Mr. Victor', 'Taussig, Mrs. Emil (Tillie Mandelbaum)', 'de Messemaeker, Mrs. Guillaume Joseph (Emma)', 'Morrow, Mr. Thomas Rowan', 'Sivic, Mr. Husein', 'Norman, Mr. Robert Douglas', 'Simmons, Mr. John', 'Meanwell, Miss. (Marion Ogden)', 'Davies, Mr. Alfred J', 'Stoytcheff, Mr. Ilia', 'Palsson, Mrs. Nils (Alma Cornelia Berglund)', 'Doharr, Mr. Tannous', 'Jonsson, Mr. Carl', 'Harris, Mr. George', 'Appleton, Mrs. Edward Dale (Charlotte Lamson)', '\"Flynn, Mr. John Irwin (\"\"Irving\"\")\"', 'Kelly, Miss. Mary', 'Rush, Mr. Alfred George John', 'Patchett, Mr. George', 'Garside, Miss. Ethel', 'Silvey, Mrs. William Baird (Alice Munger)', 'Caram, Mrs. Joseph (Maria Elias)', 'Jussila, Mr. Eiriik', 'Christy, Miss. Julie Rachel', 'Thayer, Mrs. John Borland (Marian Longstreth Morris)', 'Downton, Mr. William James', 'Ross, Mr. John Hugo', 'Paulner, Mr. Uscher', 'Taussig, Miss. Ruth', 'Jarvis, Mr. John Denzil', 'Frolicher-Stehli, Mr. Maxmillian', 'Gilinski, Mr. Eliezer', 'Murdlin, Mr. Joseph', 'Rintamaki, Mr. Matti', 'Stephenson, Mrs. Walter Bertram (Martha Eustis)', 'Elsbury, Mr. William James', 'Bourke, Miss. Mary', 'Chapman, Mr. John Henry', 'Van Impe, Mr. Jean Baptiste', 'Leitch, Miss. Jessie Wills', 'Johnson, Mr. Alfred', 'Boulos, Mr. Hanna', '\"Duff Gordon, Sir. Cosmo Edmund (\"\"Mr Morgan\"\")\"', 'Jacobsohn, Mrs. Sidney Samuel (Amy Frances Christy)', 'Slabenoff, Mr. Petco', 'Harrington, Mr. Charles H', 'Torber, Mr. Ernst William', '\"Homer, Mr. Harry (\"\"Mr E Haven\"\")\"', 'Lindell, Mr. Edvard Bengtsson', 'Karaic, Mr. Milan', 'Daniel, Mr. Robert Williams', 'Laroche, Mrs. Joseph (Juliette Marie Louise Lafargue)', 'Shutes, Miss. Elizabeth W', 'Andersson, Mrs. Anders Johan (Alfrida Konstantia Brogren)', 'Jardin, Mr. Jose Neto', 'Murphy, Miss. Margaret Jane', 'Horgan, Mr. John', 'Brocklebank, Mr. William Alfred', 'Herman, Miss. Alice', 'Danbom, Mr. Ernst Gilbert', 'Lobb, Mrs. William Arthur (Cordelia K Stanlick)', 'Becker, Miss. Marion Louise', 'Gavey, Mr. Lawrence', 'Yasbeck, Mr. Antoni', 'Kimball, Mr. Edwin Nelson Jr', 'Nakid, Mr. Sahid', 'Hansen, Mr. Henry Damsgaard', '\"Bowen, Mr. David John \"\"Dai\"\"\"', 'Sutton, Mr. Frederick', 'Kirkland, Rev. Charles Leonard', 'Longley, Miss. Gretchen Fiske', 'Bostandyeff, Mr. Guentcho', \"O'Connell, Mr. Patrick D\", 'Barkworth, Mr. Algernon Henry Wilson', 'Lundahl, Mr. Johan Svensson', 'Stahelin-Maeglin, Dr. Max', 'Parr, Mr. William Henry Marsh', 'Skoog, Miss. Mabel', 'Davis, Miss. Mary', 'Leinonen, Mr. Antti Gustaf', 'Collyer, Mr. Harvey', 'Panula, Mrs. Juha (Maria Emilia Ojala)', 'Thorneycroft, Mr. Percival', 'Jensen, Mr. Hans Peder', 'Sagesser, Mlle. Emma', 'Skoog, Miss. Margit Elizabeth', 'Foo, Mr. Choong', 'Baclini, Miss. Eugenie', 'Harper, Mr. Henry Sleeper', 'Cor, Mr. Liudevit', 'Simonius-Blumer, Col. Oberst Alfons', 'Willey, Mr. Edward', 'Stanley, Miss. Amy Zillah Elsie', 'Mitkoff, Mr. Mito', 'Doling, Miss. Elsie', 'Kalvik, Mr. Johannes Halvorsen', '\"O\\'Leary, Miss. Hanora \"\"Norah\"\"\"', '\"Hegarty, Miss. Hanora \"\"Nora\"\"\"', 'Hickman, Mr. Leonard Mark', 'Radeff, Mr. Alexander', 'Bourke, Mrs. John (Catherine)', 'Eitemiller, Mr. George Floyd', 'Newell, Mr. Arthur Webster', 'Frauenthal, Dr. Henry William', 'Badt, Mr. Mohamed', 'Colley, Mr. Edward Pomeroy', 'Coleff, Mr. Peju', 'Lindqvist, Mr. Eino William', 'Hickman, Mr. Lewis', 'Butler, Mr. Reginald Fenton', 'Rommetvedt, Mr. Knud Paust', 'Cook, Mr. Jacob', 'Taylor, Mrs. Elmer Zebley (Juliet Cummins Wright)', 'Brown, Mrs. Thomas William Solomon (Elizabeth Catherine Ford)', 'Davidson, Mr. Thornton', 'Mitchell, Mr. Henry Michael', 'Wilhelms, Mr. Charles', 'Watson, Mr. Ennis Hastings', 'Edvardsson, Mr. Gustaf Hjalmar', 'Sawyer, Mr. Frederick Charles', 'Turja, Miss. Anna Sofia', 'Goodwin, Mrs. Frederick (Augusta Tyler)', 'Cardeza, Mr. Thomas Drake Martinez', 'Peters, Miss. Katie', 'Hassab, Mr. Hammad', 'Olsvigen, Mr. Thor Anderson', 'Goodwin, Mr. Charles Edward', 'Brown, Mr. Thomas William Solomon', 'Laroche, Mr. Joseph Philippe Lemercier', 'Panula, Mr. Jaako Arnold', 'Dakic, Mr. Branko', 'Fischer, Mr. Eberhard Thelander', 'Madill, Miss. Georgette Alexandra', 'Dick, Mr. Albert Adrian', 'Karun, Miss. Manca', 'Lam, Mr. Ali', 'Saad, Mr. Khalil', 'Weir, Col. John', 'Chapman, Mr. Charles Henry', 'Kelly, Mr. James', '\"Mullens, Miss. Katherine \"\"Katie\"\"\"', 'Thayer, Mr. John Borland', 'Humblen, Mr. Adolf Mathias Nicolai Olsen', 'Astor, Mrs. John Jacob (Madeleine Talmadge Force)', 'Silverthorne, Mr. Spencer Victor', 'Barbara, Miss. Saiide', 'Gallagher, Mr. Martin', 'Hansen, Mr. Henrik Juul', '\"Morley, Mr. Henry Samuel (\"\"Mr Henry Marshall\"\")\"', '\"Kelly, Mrs. Florence \"\"Fannie\"\"\"', 'Calderhead, Mr. Edward Pennington', 'Cleaver, Miss. Alice', '\"Moubarek, Master. Halim Gonios (\"\"William George\"\")\"', '\"Mayne, Mlle. Berthe Antonine (\"\"Mrs de Villiers\"\")\"', 'Klaber, Mr. Herman', 'Taylor, Mr. Elmer Zebley', 'Larsson, Mr. August Viktor', 'Greenberg, Mr. Samuel', 'Soholt, Mr. Peter Andreas Lauritz Andersen', 'Endres, Miss. Caroline Louise', '\"Troutt, Miss. Edwina Celia \"\"Winnie\"\"\"', 'McEvoy, Mr. Michael', 'Johnson, Mr. Malkolm Joackim', '\"Harper, Miss. Annie Jessie \"\"Nina\"\"\"', 'Jensen, Mr. Svend Lauritz', 'Gillespie, Mr. William Henry', 'Hodges, Mr. Henry Price', 'Chambers, Mr. Norman Campbell', 'Oreskovic, Mr. Luka', 'Renouf, Mrs. Peter Henry (Lillian Jefferys)', 'Mannion, Miss. Margareth', 'Bryhl, Mr. Kurt Arnold Gottfrid', 'Ilmakangas, Miss. Pieta Sofia', 'Allen, Miss. Elisabeth Walton', 'Hassan, Mr. Houssein G N', 'Knight, Mr. Robert J', 'Berriman, Mr. William John', 'Troupiansky, Mr. Moses Aaron', 'Williams, Mr. Leslie', 'Ford, Mrs. Edward (Margaret Ann Watson)', 'Lesurer, Mr. Gustave J', 'Ivanoff, Mr. Kanio', 'Nankoff, Mr. Minko', 'Hawksford, Mr. Walter James', 'Cavendish, Mr. Tyrell William', '\"Ryerson, Miss. Susan Parker \"\"Suzette\"\"\"', 'McNamee, Mr. Neal', 'Stranden, Mr. Juho', 'Crosby, Capt. Edward Gifford', 'Abbott, Mr. Rossmore Edward', 'Sinkkonen, Miss. Anna', 'Marvin, Mr. Daniel Warner', 'Connaghton, Mr. Michael', 'Wells, Miss. Joan', 'Moor, Master. Meier', 'Vande Velde, Mr. Johannes Joseph', 'Jonkoff, Mr. Lalio', 'Herman, Mrs. Samuel (Jane Laver)', 'Hamalainen, Master. Viljo', 'Carlsson, Mr. August Sigfrid', 'Bailey, Mr. Percy Andrew', 'Theobald, Mr. Thomas Leonard', 'Rothes, the Countess. of (Lucy Noel Martha Dyer-Edwards)', 'Garfirth, Mr. John', 'Nirva, Mr. Iisakki Antino Aijo', 'Barah, Mr. Hanna Assi', 'Carter, Mrs. William Ernest (Lucile Polk)', 'Eklund, Mr. Hans Linus', 'Hogeboom, Mrs. John C (Anna Andrews)', 'Brewe, Dr. Arthur Jackson', 'Mangan, Miss. Mary', 'Moran, Mr. Daniel J', 'Gronnestad, Mr. Daniel Danielsen', 'Lievens, Mr. Rene Aime', 'Jensen, Mr. Niels Peder', 'Mack, Mrs. (Mary)', 'Elias, Mr. Dibo', 'Hocking, Mrs. Elizabeth (Eliza Needs)', 'Myhrman, Mr. Pehr Fabian Oliver Malkolm', 'Tobin, Mr. Roger', 'Emanuel, Miss. Virginia Ethel', 'Kilgannon, Mr. Thomas J', 'Robert, Mrs. Edward Scott (Elisabeth Walton McMillan)', 'Ayoub, Miss. Banoura', 'Dick, Mrs. Albert Adrian (Vera Gillespie)', 'Long, Mr. Milton Clyde', 'Johnston, Mr. Andrew G', 'Ali, Mr. William', 'Harmer, Mr. Abraham (David Lishin)', 'Sjoblom, Miss. Anna Sofia', 'Rice, Master. George Hugh', 'Dean, Master. Bertram Vere', 'Guggenheim, Mr. Benjamin', '\"Keane, Mr. Andrew \"\"Andy\"\"\"', 'Gaskell, Mr. Alfred', 'Sage, Miss. Stella Anna', 'Hoyt, Mr. William Fisher', 'Dantcheff, Mr. Ristiu', 'Otter, Mr. Richard', 'Leader, Dr. Alice (Farnham)', 'Osman, Mrs. Mara', 'Ibrahim Shawah, Mr. Yousseff', 'Van Impe, Mrs. Jean Baptiste (Rosalie Paula Govaert)', 'Ponesell, Mr. Martin', 'Collyer, Mrs. Harvey (Charlotte Annie Tate)', 'Carter, Master. William Thornton II', 'Thomas, Master. Assad Alexander', 'Hedman, Mr. Oskar Arvid', 'Johansson, Mr. Karl Johan', 'Andrews, Mr. Thomas Jr', 'Pettersson, Miss. Ellen Natalia', 'Meyer, Mr. August', 'Chambers, Mrs. Norman Campbell (Bertha Griggs)', 'Alexander, Mr. William', 'Lester, Mr. James', 'Slemen, Mr. Richard James', 'Andersson, Miss. Ebba Iris Alfrida', 'Tomlin, Mr. Ernest Portage', 'Fry, Mr. Richard', 'Heininen, Miss. Wendla Maria', 'Mallet, Mr. Albert', 'Holm, Mr. John Fredrik Alexander', 'Skoog, Master. Karl Thorsten', 'Hays, Mrs. Charles Melville (Clara Jennings Gregg)', 'Lulic, Mr. Nikola', 'Reuchlin, Jonkheer. John George', 'Moor, Mrs. (Beila)', 'Panula, Master. Urho Abraham', 'Flynn, Mr. John', 'Lam, Mr. Len', 'Mallet, Master. Andre', 'McCormack, Mr. Thomas Joseph', 'Stone, Mrs. George Nelson (Martha Evelyn)', 'Yasbeck, Mrs. Antoni (Selini Alexander)', 'Richards, Master. George Sibley', 'Saad, Mr. Amin', 'Augustsson, Mr. Albert', 'Allum, Mr. Owen George', 'Compton, Miss. Sara Rebecca', 'Pasic, Mr. Jakob', 'Sirota, Mr. Maurice', 'Chip, Mr. Chang', 'Marechal, Mr. Pierre', 'Alhomaki, Mr. Ilmari Rudolf', 'Mudd, Mr. Thomas Charles', 'Serepeca, Miss. Augusta', 'Lemberopolous, Mr. Peter L', 'Culumovic, Mr. Jeso', 'Abbing, Mr. Anthony', 'Sage, Mr. Douglas Bullen', 'Markoff, Mr. Marin', 'Harper, Rev. John', 'Goldenberg, Mrs. Samuel L (Edwiga Grabowska)', 'Andersson, Master. Sigvard Harald Elias', 'Svensson, Mr. Johan', 'Boulos, Miss. Nourelain', 'Lines, Miss. Mary Conover', 'Carter, Mrs. Ernest Courtenay (Lilian Hughes)', 'Aks, Mrs. Sam (Leah Rosen)', 'Wick, Mrs. George Dennick (Mary Hitchcock)', 'Daly, Mr. Peter Denis ', 'Baclini, Mrs. Solomon (Latifa Qurban)', 'Razi, Mr. Raihed', 'Hansen, Mr. Claus Peter', 'Giles, Mr. Frederick Edward', 'Swift, Mrs. Frederick Joel (Margaret Welles Barron)', '\"Sage, Miss. Dorothy Edith \"\"Dolly\"\"\"', 'Gill, Mr. John William', 'Bystrom, Mrs. (Karolina)', 'Duran y More, Miss. Asuncion', 'Roebling, Mr. Washington Augustus II', 'van Melkebeke, Mr. Philemon', 'Johnson, Master. Harold Theodor', 'Balkic, Mr. Cerin', 'Beckwith, Mrs. Richard Leonard (Sallie Monypeny)', 'Carlsson, Mr. Frans Olof', 'Vander Cruyssen, Mr. Victor', 'Abelson, Mrs. Samuel (Hannah Wizosky)', '\"Najib, Miss. Adele Kiamie \"\"Jane\"\"\"', 'Gustafsson, Mr. Alfred Ossian', 'Petroff, Mr. Nedelio', 'Laleff, Mr. Kristo', 'Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)', 'Shelley, Mrs. William (Imanita Parrish Hall)', 'Markun, Mr. Johann', 'Dahlberg, Miss. Gerda Ulrika', 'Banfield, Mr. Frederick James', 'Sutehall, Mr. Henry Jr', 'Rice, Mrs. William (Margaret Norton)', 'Montvila, Rev. Juozas', 'Graham, Miss. Margaret Edith', '\"Johnston, Miss. Catherine Helen \"\"Carrie\"\"\"', 'Behr, Mr. Karl Howell', 'Dooley, Mr. Patrick']\n"
     ]
    }
   ],
   "source": [
    "# Extract only the names from the full data, which is the fourth column\n",
    "\n",
    "names = titanic_rdd.map(lambda x: x[3])\n",
    "print(names.collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a3b999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "# Total number of passengers in the dataset (.count())\n",
    "\n",
    "passenger_count = titanic_rdd.count()\n",
    "print(passenger_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66216ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n"
     ]
    }
   ],
   "source": [
    "# How many people were in first class? (Pclass, third column) (.count() function)\n",
    "\n",
    "titanic_first_class_count = titanic_rdd.filter(lambda row: row[2] == 1) \\\n",
    "                    .count()\n",
    "print(titanic_first_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00393f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hány ember volt, akik nem élték túl a Titanic tragédiáját? (.count() függvény segítségével)\n",
    "\n",
    "titanic_rdd.map(lambda row: int(row[1])) \\\n",
    "           .filter(lambda survived: survived == 0) \\\n",
    "           .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a87a9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First class survival rate: 0.39766081871345027\n",
      "Second class survival rate: 0.2543859649122807\n",
      "Third class survival rate: 0.347953216374269\n"
     ]
    }
   ],
   "source": [
    "# What proportion of first class passengers survived compared to second and third class? (.count())\n",
    "\n",
    "first_class_survived_count = titanic_rdd \\\n",
    "                            .filter(lambda row: row[2] == 1 and row[1] == 1) \\\n",
    "                            .count()\n",
    "second_class_survived_count = titanic_rdd \\\n",
    "                            .filter(lambda row: row[2] == 2 and row[1] == 1) \\\n",
    "                            .count()\n",
    "third_class_survived_count = titanic_rdd \\\n",
    "                            .filter(lambda row: row[2] == 3 and row[1] == 1) \\\n",
    "                            .count()\n",
    "total_survived_count = titanic_rdd \\\n",
    "                      .map(lambda row: int(row[1])) \\\n",
    "                      .filter(lambda survived: survived == 1) \\\n",
    "                      .count()\n",
    "print(f\"First class survival rate: {first_class_survived_count / total_survived_count}\")\n",
    "print(f\"Second class survival rate: {second_class_survived_count / total_survived_count}\")\n",
    "print(f\"Third class survival rate: {third_class_survived_count / total_survived_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1967a2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male: 0.5648148148148148\n",
      "female: 0.4351851851851852\n"
     ]
    }
   ],
   "source": [
    "# What was the ratio of women to men in first class? (.count() function)\n",
    "\n",
    "first_class_male_count = titanic_rdd \\\n",
    "                         .filter(lambda row: row[2] == 1 and row[4] == \"male\") \\\n",
    "                         .count()\n",
    "first_class_female_count = titanic_rdd \\\n",
    "                           .filter(lambda row: row[2] == 1 and row[4] == \"female\") \\\n",
    "                           .count()\n",
    "total_first_class_count = titanic_rdd \\\n",
    "                           .filter(lambda row: row[2] == 1) \\\n",
    "                           .count()\n",
    "print(f\"male: {first_class_male_count/total_first_class_count}\")\n",
    "print(f\"female: {first_class_female_count/total_first_class_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a704d",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59b823c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (591941054.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\erick\\AppData\\Local\\Temp\\ipykernel_23080\\591941054.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    names = titanic_rdd.(lambda x: x[3])\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Extract only the names from the total data, which is the fourth column\n",
    "\n",
    "names = titanic_rdd.(lambda x: x[3])\n",
    "print(names.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39406deb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (655012066.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\erick\\AppData\\Local\\Temp\\ipykernel_23080\\655012066.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    passenger_count = titanic_rdd.\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Total number of passengers in the dataset? \n",
    "\n",
    "passenger_count = titanic_rdd.\n",
    "print(passenger_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00df39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many people were in first class? (Pclass, third column) \n",
    "\n",
    "titanic_first_class_count = titanic_rdd.filter(lambda row: ) \\\n",
    "                    .count()\n",
    "print(titanic_first_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc68013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many people did not survive the Titanic tragedy? (.count() function) \n",
    "\n",
    "titanic_rdd.map(lambda row: int(row[1])) \\\n",
    "           .filter( == 0) \\\n",
    "           . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What proportion of first class passengers survived compared to second and third class? (.count())\n",
    "\n",
    "first_class_survived_count = titanic_rdd \\\n",
    "                            .filter(lambda row: row[2] == 1 and row[1] == 1) \\\n",
    "                            .count()\n",
    "second_class_survived_count = titanic_rdd \\\n",
    "                            . \\\n",
    "                            .\n",
    "third_class_survived_count = titanic_rdd \\\n",
    "                            . \\\n",
    "                            .\n",
    "total_survived_count = titanic_rdd \\\n",
    "                      \n",
    "print(f\"First class survival rate: {first_class_survived_count / total_survived_count}\")\n",
    "print(f\"Second class survival rate: {second_class_survived_count / total_survived_count}\")\n",
    "print(f\"Third class survival rate: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the ratio of women to men in first class? (.count() function)\n",
    "\n",
    "first_class_male_count = titanic_rdd \\\n",
    "                         .filter(lambda row: row[2] == 1 and \n",
    "                         .count()\n",
    "first_class_female_count = titanic_rdd \\\n",
    "                           \n",
    "total_first_class_count = titanic_rdd \\\n",
    "                           .filter(lambda row: row[2] == 1) \\\n",
    "                           .count()\n",
    "print(f\"male: {first_class_male_count/total_first_class_count}\")\n",
    "print(f\"female: {first_class_female_count/total_first_class_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c7f9e",
   "metadata": {},
   "source": [
    "### map and reduce function together\n",
    "\n",
    "PySpark RDDs use the Hadoop-like __MapReduce__ pattern to transform and aggregate data. The transformation is the Map operation, while the aggregation is the Reduce operation. The transformation and aggregation operations are performed in a sequence on PySpark RDDs.\n",
    "\n",
    "The steps in the MapReduce pattern are as follows:\n",
    "\n",
    "- Convert: the RDD is converted to another RDD using the Map operation.\n",
    "- Aggregate: The RDD is aggregated using the Reduce operation.\n",
    "\n",
    "The general syntax of the Map and Reduce operations is as follows:\n",
    "\n",
    "```python\n",
    "rdd.map(lambda x: f(x)).reduce(lambda x, y: g(x, y))\n",
    "```\n",
    "\n",
    "Where rdd is an RDD, f(x) is a transformation function, g(x,y) is an aggregation function, and lambda is a lambda expression representing the functions f and g.\n",
    "\n",
    "The map operation applies the function f to each element of the RDD and creates a new RDD from the results. The reduce operation converts the new RDD to a single value using the function g.\n",
    "\n",
    "For example, if we want to add an RDD, the MapReduce pattern looks like this:\n",
    "\n",
    "\n",
    "```python\n",
    "rdd.map(lambda x: x).reduce(lambda x, y: x + y)\n",
    "```\n",
    "\n",
    "This simple example sums all the elements of the RDD. The elements of the RDD are not modified in the map operation, they are just passed to the reduce operation where all elements are summed.\n",
    "\n",
    "This is a simple example, but the MapReduce pattern is very efficient for aggregating and transforming large data sets. The PySpark RDDs provide very powerful tools for using the MapReduce pattern, allowing users to analyze large data sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf98eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the age of the youngest passenger on board? (using map and reduce functions)\n",
    "\n",
    "youngest_age = titanic_rdd \\\n",
    "               .map(lambda row: row[5]) \\\n",
    "               .filter(lambda age: age != None ) \\\n",
    "               .reduce(lambda age1, age2: min(age1, age2))\n",
    "print(f\"Youngest passenger age: {youngest_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5fbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many passengers whose age could not be mapped on board?\n",
    "\n",
    "traveller_count = titanic_rdd \\\n",
    "                    .map(lambda row: 1) \\\n",
    "                    .reduce(lambda count1, count2: count1 + count2)\n",
    "print(f\"Traveller count: {traveller_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f4933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many passengers whose age could not be mapped on board?\n",
    "\n",
    "unknown_age_count = titanic_rdd \\\n",
    "                    .map(lambda row: row[5]) \\\n",
    "                    .filter(lambda age: age == None) \\\n",
    "                    .map(lambda age: 1) \\\n",
    "                    .reduce(lambda count1, count2: count1 + count2)\n",
    "print(f\"Unknown age count: {unknown_age_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please show the names of all passengers in the Titanic database, \n",
    "# and then convert them to upper case using the map function.\n",
    "\n",
    "passenger_names = titanic_rdd \\\n",
    "                 .map(lambda row: row[3]) \\\n",
    "                 .map(lambda name: name.upper()) \\\n",
    "                 .collect()\n",
    "print(passenger_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba0374",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the age of the youngest passenger on board? (using map and reduce functions)\n",
    "\n",
    "youngest_age = titanic_rdd \\\n",
    "               .map(lambda row: row[5]) \\\n",
    "               .filter(lambda age: age != None ) \\\n",
    "               .reduce(\n",
    "    \n",
    "    \n",
    "print(f\"Youngest passenger age: {youngest_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b13f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the age of the oldest passenger on board? (using map and reduce functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of passengers (using map and reduce functions)\n",
    "\n",
    "traveller_count = titanic_rdd \\\n",
    "                    .map(lambda row: 1) \\\n",
    "                    .reduce(\n",
    "    \n",
    "    \n",
    "print(f\"Traveller count: {traveller_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac252c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many passengers whose age could not be mapped on board?\n",
    "\n",
    "unknown_age_count = titanic_rdd \\\n",
    "                    .map(lambda row: row[5]) \\\n",
    "                    .filter(\n",
    "    \n",
    "    \n",
    "print(f\"Unknown age count: {unknown_age_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814de139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please show the names of all passengers in the Titanic database, \n",
    "# and then convert them to lowercase using the map function.\n",
    "\n",
    "passenger_names = titanic_rdd \\\n",
    "                 .map\n",
    "\n",
    "\n",
    "print(passenger_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a57607",
   "metadata": {},
   "source": [
    "### sortBy function\n",
    "\n",
    "The sortBy function is one of the functions of the PySpark RDD class, which can be used to sort RDD elements by key or value. The first parameter of the sortBy function is the key function, which is used to specify the sorting criteria. The second parameter can be set to False if descending ordering is required, and the default is ascending ordering.\n",
    "\n",
    "```python\n",
    "# Create an RDD containing strings\n",
    "rdd = sc.parallelize([\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\", \"fig\"])\n",
    "\n",
    "# Arrange the RDD in ascending order by the length of the strings\n",
    "sorted_rdd = rdd.sortBy(lambda x: len(x))\n",
    "\n",
    "# Print the result\n",
    "print(sorted_rdd.collect())\n",
    "```\n",
    "Result:\n",
    "```\n",
    "['fig', 'date', 'apple', 'banana', 'cherry', 'elderberry']\n",
    "```\n",
    "In the above example, we have sorted the elements of the RDD in ascending order by the length of the strings using the sortBy function. In the result, the elements of the RDD are sorted by the initial letter if they are of the same length. The collect function is used to print the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9246d96",
   "metadata": {},
   "source": [
    "### take function\n",
    "\n",
    "The take function is a PySpark operation that returns the first n elements of the RDD in the form of a list. This function can be useful when examining the RDD, as it is not necessary to iterate over all the elements, but only the first few. Here is an example of using the take function:\n",
    "\n",
    "```python\n",
    "# Create an RDD with numbers\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Take the first 3 elements from the RDD\n",
    "result = rdd.take(3)\n",
    "\n",
    "# Write the result\n",
    "print(result)\n",
    "```\n",
    "Result:\n",
    "```python\n",
    "[1, 2, 3]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the ages of the first 10 passengers in the Titanic dataset! \n",
    "# Use the map function to retrieve the ages, filter out those with None, \n",
    "# then sort them in ascending order and select the first 10.\n",
    "\n",
    "first_10_ages = titanic_rdd \\\n",
    "                .map(lambda row: row[5]) \\\n",
    "                .filter(lambda age: age != None) \\\n",
    "                .map(lambda age: age) \\\n",
    "                .sortBy(lambda age: age) \\\n",
    "                .take(10)\n",
    "print(first_10_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815bc683",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c214093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the ages of the first 5 passengers in the Titanic dataset! \n",
    "# Use the map function to retrieve the ages, filter out those with None, \n",
    "# then sort them in descending order and select the first 5.\n",
    "\n",
    "first_10_ages = titanic_rdd \\\n",
    "                .map(lambda row: row[5]) \\\n",
    "                .filter(lambda age: age != None) \\\n",
    "                .map(lambda age: age) \\\n",
    "                .sortBy(\n",
    "                .take\n",
    "print(first_10_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3b80e",
   "metadata": {},
   "source": [
    "### partitioning\n",
    "\n",
    "PySpark RDDs can be divided into parts, called partitions, into which the elements of the RDD are grouped. The number of particles can be set when the RDD is created or will be the default number set in the Spark context.\n",
    "\n",
    "The role of partitioning is to divide the RDD into independent parts in the Spark cluster that can be processed in parallel. This allows Spark to make efficient use of available resources and process RDD elements faster.\n",
    "\n",
    "Partitioning the RDD can be advantageous when the RDD is large or when you want to perform operations that allow parallel execution.\n",
    "\n",
    "Partitioning of the RDD can be performed using the repartition or coalesce functions. The repartition function reorganizes the RDD to the specified number of partitions, while the coalesce function reorganizes the RDD to the default partitioning level.\n",
    "\n",
    "```python\n",
    "# Create an RDD with numbers\n",
    "rdd = sc.parallelize(range(100), numSlices=4)\n",
    "\n",
    "# Set the partitioning number to 2\n",
    "rdd = rdd.repartition(2)\n",
    "\n",
    "# Examine the number of partitions\n",
    "print(rdd.getNumPartitions())\n",
    "\n",
    "```\n",
    "Result:\n",
    "\n",
    "```python\n",
    "2\n",
    "\n",
    "```\n",
    "\n",
    "In the above example, we first create an RDD with numbers, and then set the number of partitions to 4 using the numSlices parameter of the parallelize function. Then, using the repartition function, we transform the RDD to contain only 2 partitions. Finally, the getNumPartitions function is used to check the number of partitions and make sure that it is set to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the number of partitions\n",
    "\n",
    "titanic_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_rdd.repartition(15).getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a56a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please describe how much data the particles contain\n",
    "\n",
    "partition_sizes = titanic_rdd.repartition(15).repartition(3).mapPartitions(lambda partition: [len(list(partition))]).collect()\n",
    "print(partition_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a2922",
   "metadata": {},
   "source": [
    "### distinct function\n",
    "\n",
    "The distinct function in PySpark is an operation on the RDD that removes duplicate elements and keeps only unique elements. The function does not perform any aggregation during its operation, i.e. the order and number of elements in the result is the same as the unique elements in the RDD.\n",
    "\n",
    "The use of the distinct function is very simple, just call it on the RDD you want to apply it to and you will get the RDD with the unique elements. In the following example we will filter out the unique elements of the RDD:\n",
    "    \n",
    "```python\n",
    "# Create RDD\n",
    "rdd = sc.parallelize([1, 2, 3, 2, 1, 4, 5, 3, 6, 7, 6, 8, 9, 9])\n",
    "\n",
    "# Filter RDD to individual elements\n",
    "unique_rdd = rdd.distinct()\n",
    "\n",
    "# Write out the unique elements\n",
    "print(unique_rdd.collect())\n",
    "\n",
    "```\n",
    "Result:\n",
    "\n",
    "```python\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c78c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please describe the different passenger classes without repeating\n",
    "\n",
    "titanic_rdd.map(lambda x: x[2]) \\\n",
    "           .distinct()          \\\n",
    "           .foreach(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696b22c",
   "metadata": {},
   "source": [
    "### union function\n",
    "\n",
    "The union function is used in PySpark to join two RDDs. When the function operates, the elements of the first RDD in the result will follow the elements of the second RDD, and the result RDD will be of the same type as the two input RDDs.\n",
    "\n",
    "Using the union function is very simple, just call it on the two RDDs you want to apply it to, and the elements of the first RDD will follow the elements of the second RDD in the result. In the following example, two RDDs are merged:  \n",
    "```python\n",
    "# Create the first RDD\n",
    "rdd1 = sc.parallelize([1, 2, 3, 4, 5])\n",
    "\n",
    "# Create the second RDD\n",
    "rdd2 = sc.parallelize([6, 7, 8, 9, 10])\n",
    "\n",
    "# Merge the RDDs\n",
    "union_rdd = rdd1.union(rdd2)\n",
    "\n",
    "# Print the result\n",
    "print(union_rdd.collect())\n",
    "\n",
    "\n",
    "```\n",
    "Result:\n",
    "\n",
    "```python\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please describe men and women separately and then combine the two RDDs with a union function.\n",
    "\n",
    "male_rdd = titanic_rdd.filter(lambda row: row[4] == \"male\")\n",
    "female_rdd = titanic_rdd.filter(lambda row: row[4] == \"female\")\n",
    "\n",
    "male_and_female = male_rdd.union(female_rdd)\n",
    "\n",
    "print(male_and_female.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e23f72c",
   "metadata": {},
   "source": [
    "### reduceByKey function\n",
    "\n",
    "The reduceByKey() function in PySpark is a transformation that can be applied to key-value pairs. The function takes an RDD stored in a key-value pair and returns another RDD in which the values associated with the keys are aggregated.\n",
    "\n",
    "The reduceByKey() function is extremely simple to use. First, an RDD with key-value pairs must be created. Then apply the reduceByKey() function to the RDD, passing the reducing function as the first argument. The reducing function has two inputs and returns an output of the same type.\n",
    "\n",
    "In the example below, an RDD is created in which the frequency of occurrence of each letter is calculated:  \n",
    "```python\n",
    "# Create RDD with key-value pairs\n",
    "rdd = sc.parallelize(['a', 'b', 'c', 'a', 'b', 'a', 'd', 'b', 'c'])\n",
    "\n",
    "# Create key-value pairs\n",
    "key_value_rdd = rdd.map(lambda x: (x, 1))\n",
    "\n",
    "# Aggregate keys by values\n",
    "sums_rdd = key_value_rdd.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Print the result\n",
    "print(sums_rdd.collect())\n",
    "\n",
    "\n",
    "```\n",
    "In the result, all occurrences are summed up by key:\n",
    "\n",
    "\n",
    "```python\n",
    "[('a', 3), ('b', 3), ('c', 2), ('d', 1)]\n",
    "\n",
    "```\n",
    "\n",
    "### reduceByKey comparison with groupByKey\n",
    "\n",
    "The reduceByKey() and groupByKey() functions are both used for aggregation in Spark. However, there are differences between the two functions:\n",
    "\n",
    "groupByKey(): aggregates all the values for a given key into a given list and returns the keys and their associated values. It groups all the values associated with a key into a single iterable object (for example, a list) and returns this object with the keys. If the input RDD is very large, the groupByKey() operation may cause memory problems, since it puts all values into a single list.\n",
    "\n",
    "reduceByKey(): Collect the values associated with the given keys and then apply the reduce() function to all the values assigned to the key. It then returns an RDD containing the keys and the aggregated values. The reduceByKey() operation allows Spark to pre-aggregate the data by key during partitioning, thus reducing communication between partitions and the memory required.\n",
    "\n",
    "So the main difference is that reduceByKey() pre-partitions the data before aggregation and reduces memory requirements, whereas groupByKey() stores all values in a single list, which can cause memory problems for large amounts of data. In addition, reduceByKey() may be more efficient if the function used for aggregation is computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Map-reduceByKey to count how many people travelled in which class?\n",
    "\n",
    "class_travelers = titanic_rdd.filter(lambda row: row[2] != None) \\\n",
    "                             .map(lambda x: (x[2],1)) \\\n",
    "                             .reduceByKey(lambda a, b: a + b) \\\n",
    "                             .collect()\n",
    "\n",
    "print(class_travelers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe410962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Map-groupByKey to count how many people travelled in which class?\n",
    "\n",
    "class_travelers = titanic_rdd.filter(lambda row: row[2] != None) \\\n",
    "                             .map(lambda x: (x[2],1)) \\\n",
    "                             .groupByKey().mapValues(sum) \\\n",
    "                             .collect()\n",
    "\n",
    "print(class_travelers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b25e08",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ccb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the titanic dataset into 15 partitions, then partition it back into 1 partition. \n",
    "\n",
    "# At the end, ask how many particles it consists of. \n",
    "\n",
    "15_part_rdd = titanic_rdd.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a2a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please describe the different passenger classes without repeating\n",
    "\n",
    "titanic_rdd.map(lambda x: x[2]) \\\n",
    "           .\n",
    "           .foreach(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please describe men and women separately and then combine the two RDDs with a union function.\n",
    "\n",
    "male_rdd = titanic_rdd.filter(lambda row: row[4] == \"male\")\n",
    "female_rdd = titanic_rdd.filter(lambda row: row[4] == \"female\")\n",
    "\n",
    "male_and_female = female_rdd.\n",
    "\n",
    "print(male_and_female.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44df307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Map-reduceByKey to count how many people travelled in which class?\n",
    "\n",
    "class_travelers = titanic_rdd.filter(lambda row: row[2] != None) \\\n",
    "                             .map(lambda x: (x[2],1)) \\\n",
    "                             .reduceByKey(lambda a, b:    ) \\\n",
    "                             .collect()\n",
    "\n",
    "print(class_travelers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aac018",
   "metadata": {},
   "source": [
    "## PySpark Dataframe API\n",
    "\n",
    "The PySpark DataFrame is a structured data store representing a table of data consisting of columns, similar to the Pandas DataFrame. DataFrames have several advantages over RDDs, such as structured data management, faster operations, and support for Python Pandas-like language elements.\n",
    "\n",
    "The PySpark DataFrame API provides various functions for manipulating data, including:\n",
    "\n",
    "- Loading and saving data: the DataFrame API provides a number of functions for loading and saving data from various data sources such as CSV, JSON, Parquet, avro, etc. For example: spark.read.csv(), spark.write.parquet().\n",
    "\n",
    " - Data transformations: The DataFrame API allows you to transform data using standard SQL operations such as SELECT, WHERE, GROUP BY, JOIN, UNION, etc. For example: df.select(), df.filter(), df.groupBy(), df.join().\n",
    "\n",
    "- Aggregation and Aggregation: The DataFrame API allows aggregation and aggregation of data using various methods such as agg() and groupBy(). For example: df.groupBy().agg()\n",
    "\n",
    "- Data handling and processing: The DataFrame API allows data handling and processing, such as handling missing data, renaming columns, converting column type, etc. For example: df.na.fill(), df.withColumnRenamed(), df.withColumn()\n",
    "\n",
    "- Window functions: the DataFrame API allows you to sort and aggregate data into windows using the window() function.\n",
    "\n",
    "The DataFrame API provides additional functions, such as PySpark SQL functions. The PySpark DataFrame API can be explored in detail in the official PySpark documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read our source file\n",
    "\n",
    "titanic_df = spark.read.format(\"parquet\").load(\"/home/student/titanic_parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53cc163",
   "metadata": {},
   "source": [
    "### select function\n",
    "\n",
    "The select() method is one of the data transformations that can be used in the PySpark DataFrame API to select or rename the columns of a given DataFrame.\n",
    "\n",
    "The select() method can be used to select multiple columns at once:\n",
    "\n",
    "```python\n",
    "titanic_df.select(\"name\", \"age\").show()\n",
    "```\n",
    "\n",
    "The select() method can also be used to rename columns:\n",
    "```python\n",
    "titanic_df.select(df[\"name\"], df[\"age\"].alias(\"years\")).show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81497fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please deselect the Survived and Name columns\n",
    "\n",
    "selected = titanic_df.select(\"Survived\", \"Name\")\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee56098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please describe those who survived and their names where the name includes \"Mrs.\"\n",
    "selected = titanic_df.select(\"Survived\", \"Name\") \\\n",
    "                     .filter(titanic_df.Survived == 1) \\\n",
    "                     .filter(titanic_df.Name.contains(\"Mrs\"))\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and rename multiple columns with alias():\n",
    "selected = titanic_df.select(titanic_df[\"Survived\"].alias(\"is_alive\"), titanic_df[\"Name\"].alias(\"full_name\"))\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafad1c1",
   "metadata": {},
   "source": [
    "Columns can also be referenced using the col function, but first you need to import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select the names and ages of all passengers:\n",
    "\n",
    "titanic_df.select(col(\"Name\"), col(\"Age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d69a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's select the names, ages and embarkation dates of all passengers:\n",
    "\n",
    "titanic_df.select(col(\"Name\"), col(\"Age\"), col(\"Embarked\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select the names of all passengers, their age and whether they survived the shipwreck:\n",
    "titanic_df.select(col(\"Name\"), col(\"Age\"), col(\"Survived\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776cd19",
   "metadata": {},
   "source": [
    "The selectExpr() method allows you to use SQL-like expressions to select, transform and rename columns in a DataFrame.\n",
    "\n",
    "Example of using selectExpr() on Titanic data:\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"titanic.csv\")\n",
    "\n",
    "# use selectExpr\n",
    "df.selectExpr(\"Survived as label\", \"Age\", \"Fare\", \"Sex\", \"Embarked\", \"Pclass\", \"SibSp + Parch as FamilySize\") \\\n",
    "  .show()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "In this example, the Age, Fare, Sex, Embarked, Pclass columns are simply taken from the DataFrame, the SibSp and Parch columns are added together and renamed to the FamilySize column, and the Survived column is renamed to label.\n",
    "\n",
    "When using selectExpr(), you can specify columns as space-separated strings and modify column names with SQL-like expressions. You can also use the expr() function to specify expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name and ID of passengers with more than 5 siblings or spouses on board:\n",
    "\n",
    "titanic_df.select(\"Name\", \"PassengerId\", \"SibSp\").filter(\"SibSp > 5\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dee2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name and age of passenger younger than 50 who bought the most expensive ticket:\n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "titanic_df.select(\"Name\", \"Age\", \"Fare\").filter(\"Age < 50\").orderBy(desc(\"Fare\")).limit(1).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c1bcdd",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbf38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please select the Survived and Name columns\n",
    "\n",
    "selected = titanic_df.select()\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d42eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please describe those who survived and their names where the name includes \"Mrs\"\n",
    "\n",
    "selected = titanic_df.select(\"Survived\", \"Name\") \\\n",
    "                     .filter(\n",
    "                     .filter(   .contains(\"Mrs\"))\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns and rename them with alias():\n",
    "\n",
    "selected = titanic_df.select(titanic_df[\"Survived\"].alias(\"is_alive\"), titanic_df[\"Name\"]. (\"full_name\"))\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7512da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d53cabd",
   "metadata": {},
   "source": [
    "### withColumn function\n",
    "\n",
    "Apache Spark's withColumn() method modifies the columns in the DataFrame or adds a new column to the DataFrame.\n",
    "\n",
    "Example of adding a new column to a DataFrame:\n",
    "\n",
    "```python\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create DataFrame\n",
    "data = [(\"John\", 25), (\"Jane\", 22), (\"Bob\", 30)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "\n",
    "# Add a new column to the DataFrame\n",
    "df = df.withColumn(\"AgePlusTen\", col(\"Age\") + 10)\n",
    "\n",
    "# Show result\n",
    "df.show()\n",
    "\n",
    "```\n",
    "\n",
    "In this example, a new column named \"AgePlusTen\" has been added to the DataFrame, adding 10 to the value of the column \"Age\". The withColumn() method uses the name \"AgePlusTen\" as the third parameter for the mathematical expression required to create the new column.\n",
    "\n",
    "Example of modifying an existing column:\n",
    "\n",
    "```python\n",
    "# Create DataFrame\n",
    "data = [(\"John\", 25), (\"Jane\", 22), (\"Bob\", 30)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "\n",
    "# Change column in DataFrame\n",
    "df = df.withColumn(\"Age\", col(\"Age\") + 10)\n",
    "\n",
    "# Show result\n",
    "df.show()\n",
    "\n",
    "```\n",
    "\n",
    "In this example, the value of column \"Age\" is incremented by 10. The withColumn() method uses the name \"Age\" as the first parameter, which specifies the name of the column to modify, then uses the value of the existing column as the second parameter using the col() function, and then adds 10 to get the modified value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Name, Age and Embarked columns using col function\n",
    "\n",
    "titanic_df.select((\"Name\"), (\"Age\"), \"Embarked\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example that adds an age category column to our data using the when function\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "\n",
    "df_with_age_category = titanic_df.withColumn(\"age_category\",when(col(\"age\") < 18, \"child\").otherwise(\"adult\"))\n",
    "df_with_age_category.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example that multiplies the age by -1\n",
    "\n",
    "df_with_minus_age = titanic_df.withColumn(\"age\",col(\"age\") *-1)\n",
    "df_with_minus_age.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5ec8b",
   "metadata": {},
   "source": [
    "### withColumnRenamed\n",
    "\n",
    "The withColumnRenamed function can be used to rename an existing column in the given DataFrame. The function takes two arguments: the first is the name of the current column, and the second is the new name to rename the column to.\n",
    "\n",
    "An example of how to rename a column in the Titanic database:\n",
    "```python\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# df is the name of the Titanic DataFrame\n",
    "df = df.withColumnRenamed(\"Pclass\", \"PassengerClass\")\n",
    "\n",
    "# Applying a new name to the PassengerClass column\n",
    "df.show()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# data loading\n",
    "titanic_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"titanic.csv\")\n",
    "\n",
    "# Rename 'Name' column to 'PassengerName'\n",
    "titanic_df = titanic_df.withColumnRenamed(\"Name\", \"PassengerName\")\n",
    "\n",
    "# print the new column\n",
    "titanic_df.select(col(\"PassengerName\")).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642c1540",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31600\\3919701182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Rename the \"Embarked\" column to \"Port_of_Embarkation\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtitanic_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitanic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Embarked\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Port_of_Embarkation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtitanic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Rename the \"Embarked\" column to \"Port_of_Embarkation\":\n",
    "\n",
    "titanic_df = titanic_df.withColumnRenamed(\"Embarked\", \"Port_of_Embarkation\")\n",
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac96f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column \"SibSp\" to \"Siblings_or_Spouses_on_Board\":\n",
    "\n",
    "titanic_df = titanic_df.withColumnRenamed(\"SibSp\", \"Siblings_or_Spouses_on_Board\")\n",
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fecdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column \"Parch\" to \"Parents_or_Children_on_Board\":\n",
    "\n",
    "titanic_df = titanic_df.withColumnRenamed(\"Parch\", \"Parents_or_Children_on_Board\")\n",
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename multiple columns\n",
    "renamed_df = titanic_df.withColumnRenamed(\"Age\", \"NewAge\").withColumnRenamed(\"Name\", \"FullName\")\n",
    "renamed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e431a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all columns\n",
    "from functools import reduce\n",
    "new_column_names = [\"Col_\" + str(i) for i in titanic_df.columns]\n",
    "renamed_df = reduce(lambda df, idx: df.withColumnRenamed(df.columns[idx], new_column_names[idx]), range(len(titanic_df.columns)), titanic_df)\n",
    "renamed_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1f1d7",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example, multiplying the age by -1\n",
    "\n",
    "df_with_minus_age = titanic_df.withColumn(\"age\", )\n",
    "df_with_minus_age.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f200e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column \"Port_of_Embarkation\" to \"Embarked\":\n",
    "\n",
    "titanic_df = titanic_df.withColumnRenamed\n",
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename multiple columns NewAge -> Age, FullName-> Name\n",
    "renamed_df = titanic_df.\n",
    "renamed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ba423",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c4486b",
   "metadata": {},
   "source": [
    "### The groupBy and agg functions\n",
    "\n",
    "The groupBy and agg operations within the PySpark DataFrame API group data by a given column value and then apply different aggregation functions to the groups. These operations are extremely useful when you want to perform complex data manipulations.\n",
    "\n",
    "Here is an example of using groupby and agg with the PySpark DataFrame API:\n",
    "\n",
    "```python\n",
    "# Load data into DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "data = [(\"Alice\", \"female\", 25),\n",
    "        (\"Bob\", \"male\", 30),\n",
    "        (\"Charlie\", \"male\", 35),\n",
    "        (\"Diana\", \"female\", 40),\n",
    "        (\"Emily\", \"female\", 45)]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"name\", \"gender\", \"age\"])\n",
    "\n",
    "# Group by gender and calculate average age\n",
    "df.groupBy(\"gender\").agg(avg(\"age\").alias(\"average_age\")).show()\n",
    "\n",
    "```\n",
    "\n",
    "In this example, we load a simple data set containing the names, gender and age of people into the DataFrame. We then use the groupBy and agg functions to group by gender and calculate the average age. The result will be as follows:\n",
    "\n",
    "```python\n",
    "+------+-----------+\n",
    "|gender|average_age|\n",
    "+------+-----------+\n",
    "|female| 36.6      |\n",
    "| male | 32.5      |\n",
    "+------+-----------+\n",
    "```\n",
    "This indicates that women are on average 36.6 years old, while men are on average 32.5 years old.\n",
    "\n",
    "Of course, groupBy and agg operations can be combined with other data manipulation functions such as filter, select or orderBy. By combining the individual operations, complex data manipulation chains can be created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload our dataframe\n",
    "\n",
    "titanic_df = spark.read.format(\"parquet\").load(\"/home/student/titanic_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f352cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the maximum age by sex and class\n",
    "\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "max_age_df = titanic_df.groupBy(['Sex', 'Pclass']).agg(max('Age').alias('MaxAge'))\n",
    "\n",
    "max_age_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So can it be:\n",
    "\n",
    "titanic_df.groupBy(\"Sex\").agg({\"Age\": \"avg\", \"Fare\": \"max\"}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f675e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average price paid by all passengers per class:\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "titanic_df.groupBy(\"Pclass\").agg(avg(\"Fare\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a67598",
   "metadata": {},
   "source": [
    "### join function\n",
    "\n",
    "The join operation allows you to join two different sets of data based on a common key. In the PySpark DataFrame API, different types of join operations are available: inner join, outer join, left outer join and right outer join.\n",
    "\n",
    "Below is an example of how to join data in one table with data in another table.\n",
    "\n",
    "Suppose you have two PySpark DataFrames containing the following data:\n",
    "    \n",
    "```python\n",
    "# DataFrame 1\n",
    "df1 = spark.createDataFrame([[\n",
    "  (\"John\", \"Doe\", 35),\n",
    "  (\"Jane\", \"Doe\", 30),\n",
    "  (\"Max\", \"Smith\", 25),\n",
    "], [\"first_name\", \"last_name\", \"age\"])\n",
    "\n",
    "# DataFrame 2\n",
    "df2 = spark.createDataFrame([\n",
    "  (\"Doe\", \"Marketing\"),\n",
    "  (\"Smith\", \"Sales\"),\n",
    "], [\"last_name\", \"department\"])\n",
    "\n",
    "```\n",
    "In this example, we will link the data in table df1 to table df2 based on the last_name key. The join type will be inner join, i.e. only those rows that are found in both tables will be kept.\n",
    "```python\n",
    "# inner join\n",
    "df3 = df1.join(df2, \"last_name\", \"inner\")\n",
    "\n",
    "df3.show()\n",
    "+---------+----------+---+----------+\n",
    "|last_name|first_name|age|department|\n",
    "+---------+----------+---+----------+\n",
    "| Doe     | John     | 35| Marketing|\n",
    "| Doe     | Jane     | 30| Marketing|\n",
    "| Smith   | Max      | 25| Sales    |\n",
    "+---------+----------+---+----------+\n",
    "\n",
    "```\n",
    "The join operation will return a new DataFrame in which the two tables have been joined based on the specified key. In the example above, the last_name column was used as the key. The joined table contains the columns first_name, age and department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe53ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of joining Titanic data between two DataFrames based on the \"PassengerId\" column:\n",
    "\n",
    "# Olvassuk be az adatokat\n",
    "titanic_df = spark.read.format(\"parquet\").load(\"/home/student/titanic_parquet\")\n",
    "titanic_df.show()\n",
    "\n",
    "# Hozzunk létre egy másik DataFrame-et, ami tartalmazza a PassengerId-ket és az életkort\n",
    "age_df = titanic_df.select(\"PassengerId\", \"Age\")\n",
    "age_df.show()\n",
    "\n",
    "# Csatlakoztassuk a két DataFrame-et a PassengerId alapján\n",
    "joined_df = titanic_df.join(age_df, \"PassengerId\",\"inner\")\n",
    "joined_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90512a5",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ad4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the minimum age by sex and class\n",
    "\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "min_age_df = titanic_df.groupBy([  ]).agg(   ('Age').alias('MinAge'))\n",
    "\n",
    "min_age_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f66984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the average price paid by all passengers per class:\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "titanic_df.     .show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
